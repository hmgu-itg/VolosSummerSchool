{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "    var code_show=true; //true -> hide code at first\n",
    "\n",
    "    function code_toggle() {\n",
    "        $('div.prompt').hide(); // always hide prompt\n",
    "\n",
    "        if (code_show){\n",
    "            $('div.input').hide();\n",
    "        } else {\n",
    "            $('div.input').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    }\n",
    "    $( document ).ready(code_toggle);\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Workshop 1b: Advanced UNIX/Bash</h1><br><br>\n",
    "<i><big> File operations, pipes and subshells.</big><br><br>\n",
    "Arthur Gilly (ag15@sanger.ac.uk), Kostas Hatzikotoulas (kh9@sanger.ac.uk)</i>\n",
    "</center>\n",
    "\n",
    "**Topics covered in this tutorial**:\n",
    "\n",
    "* Text processing tools: grep, sed, cut, awk, join, tr and paste.\n",
    "* Simple variable handling.\n",
    "* Loops.\n",
    "* Conditionals.\n",
    "* Pipes, backticks and brackets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Downloading resources from the internet\n",
    "\n",
    "It is easy to access the internet via the command line. For this we use the `wget` tool. We want to  download the complete [GWAS catalog](https://www.ebi.ac.uk/gwas/) maintained by [EBI](https://www.ebi.ac.uk/) that contains all the published genome-wide associations to date. This collection by 2017.05.12 contains 29,196 SNPs and 33,898 associations publised in 2,882 research articles. You can perform simple queries on the database using the GWAS catalog website, but you can also download it so you can build you own database. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 0:</b>  Go to the GWAS catalog website and find the download link. Create a directory in your home named `GWAS_catalog` and download it to a file named `GWAS_catalog_2017.05.12`. How large is the file you just downloaded?\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Goes to your home\n",
    "cd\n",
    "\n",
    "# Creates directory and enters it\n",
    "mkdir GWAS_catalog && cd GWAS_catalog\n",
    "\n",
    "# After the URL to the dataset, we specify the output file name.\n",
    "wget https://www.ebi.ac.uk/gwas/api/search/downloads/full -O GWAS_catalog_2017.05.12\n",
    "\n",
    "# Size\n",
    "ls -lh GWAS_catalog_2017.05.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> The `&&` operator allows you to execute several commands one after the other, but only if previous ones succeed. For example `command1 && command2 && command3` will execute `command2` only if `command1` succeeded, and `command3` only if both `command1` and `command2` succeeded.\n",
    "</div>\n",
    "\n",
    "`wget` is an extremely powerful bash tool, and has a wide range of amazing features (like resuming interrupted download) that we can't cover here. As it has been mentioned in the previous workshop, you can read the comprehensive manual using `man wget`. This also apply to the rest of the tools we are covering in this session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing bash tools\n",
    "\n",
    "###  Step 2: Counting lines, first $n$ and last $n$ lines of a file\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 1:</b>  Using `wc`, check the number of lines in the GWAS catalog. Using `head` and `tail`, display the first 10 lines and the last 5 lines of the file.\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# How many lines does the file have?\n",
    "wc -l GWAS_catalog_2017.05.12\n",
    "\n",
    "# First 10 rows\n",
    "head GWAS_catalog_2017.05.12\n",
    "\n",
    "# Last 5 rows\n",
    "tail -5 GWAS_catalog_2017.05.12\n",
    "tail -n 5 GWAS_catalog_2017.05.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the first 10 rows we can see how the file is structured: \n",
    "* the first line is the header describing the content of each column (a more comprehensive explanation can be found on the [gwas website](https://www.ebi.ac.uk/gwas/docs/fileheaders))\n",
    "* then each line is an individual association between a genetic variant and an observed phenotype.\n",
    "\n",
    "### Step 3 : Using pipes\n",
    "\n",
    "Right now, all the commands we ran were printing their output to the screen (like `wc`) or to a file (`wget -O`). But we can also make the output go to another bash command. We do this using the \"pipe\" character (`|`). For example, `command1 | command2` will pass the output of `command1` to the input of `command2`. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 2:</b>  Using `head` piped to `tail`, print **only the 300th line** of the GWAS catalog. \n",
    "<br><br>\n",
    "`cat` prints the output of one or more files to the screen. Using `cat` and `wc`, print the number of lines in the GWAS catalog.\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-06-22\t18439548\tRidker PM\t2008-04-24\tAm J Hum Genet\twww.ncbi.nlm.nih.gov/pubmed/18439548\tLoci related to metabolic-syndrome pathways including LEPR,HNF1A, IL6R, and GCKR associate with plasma C-reactive protein: the Women's Genome Health Study.\tC-reactive protein\t6,345 European ancestry female individuals\tNA\t12q24.31\t12\t120987058\tHNF1A\tHNF1A\t\t\t6927\t\t\trs7310409-A\trs7310409\t0\t7310409\tintron_variant\t0\tNR\t7E-17\t16.154901959985743\t\t0.15\t[NR] mg/dl decrease\tIllumina [336108]\tN\r\n",
      "39690\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -300 GWAS_catalog_2017.05.12 | tail -1\n",
    "\n",
    "cat GWAS_catalog_2017.05.12 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : redirections\n",
    "\n",
    "Instead of ouputting the result of a command to another command, we can also tell UNIX to write the output to a file. This is not so useful when you have 1 command, but when you have several piped commands (pipeline) it is used to write the end result to a file. There are 2 types of redirection:\n",
    "\n",
    "* **overwrite** which is a single \"greater than\". `command1 > file` will overwrite `file` if it exists, otherwise create it and fill it with the output of `command1`.\n",
    "* **append**, which is a double \"greater than\". `command1 >> file` will add the output of `command1` to `file`, creating it if it does not exist.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 3:</b>  Using `head`, `tail` and pipes, create a file named `300th_line.txt` that contains **only the header and the 300th line**, and display it using `cat`.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "## First the header\n",
    "head -1 GWAS_catalog_2017.05.12 > 300th_line.txt\n",
    "\n",
    "## Then the 300th line\n",
    "head -300 GWAS_catalog_2017.05.12 | tail -1 >> 300th_line.txt\n",
    "\n",
    "cat 300th_line.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>Question 4:</b> The file you have created contains both spaces and tab characters as separators, which makes it a bit messy to display. The `column` command can add artificial spaces to a pipe, so that it looks a bit more like Excel. Pipe `cat` into `column -s$'\\t' -t`, and then into `less`. By default, `less` folds long lines to make them fit the screen. We have very long lines so we want to display them laterally, without breaking them. Can you find the option in the `less` manual that does that? The 300th line of the GWAS catalog tells us about a mutation in a gene. Can you find the chromosome, position and gene for that variant?\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat 300th_line.txt | column -s$'\\t' -t | less -S\n",
    "\n",
    "# chromosome 12     position 120987058  gene HNF1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching files\n",
    "\n",
    "Very often, we want to search the contents of files. This is done using a very powerful command, `grep`.\n",
    "\n",
    "```bash\n",
    "\n",
    "grep [OPTIONS] [PATTERN] [FILE]\n",
    "\n",
    "# Example:\n",
    "\n",
    "grep Volos cities.txt\n",
    "```\n",
    "\n",
    "the last example looks for every line that contains \"Volos\" in the file `cities.txt` and displays the corresponding row. If your pattern contains a space, enclose it within simple or double quotes (e.g. `\"Volos, Thessalia\"` or `'Volos, Thessalia'`)\n",
    "\n",
    "<div class=\"alert alert-info\"> It is possible to search for several patterns at a time, not just one. If you are interested in only a few patterns, you can add them to the command line, separating them by `-e`. For example, ` grep -e Volos -e Thessaloniki cities.txt`. If you have many patterns that you want to search for, you can use `grep -f patterns.txt file.txt` where `patterns.txt` contains all the patterns you are interested in , 1 per line.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\"> Interesting parameters for `grep` are `-w`, `-v`, `-i`, `-n`, `-A`, `-B`, `-C`, `-l` and `-L`. Check them out and play around with them if you have time!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 5:</b> Use `grep` to search for other variants in the gene you found above. Using a pipe and `wc`, determine how many lines from the GWAS ctalog mention it. How about the variant you found? Are there other lines that mention this variant?\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 6:</b> Before, we used 2 steps to create a file containing the 300th line. Now with `grep`, we can do everything in one line. Find something unique to the header and our 300th line, and create a file called `300th_line2.txt` that contains them (you might need several grep commands piped together). Use the `diff` command to check that the files are identical.\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 5\n",
    "grep HNF1A GWAS_catalog_2017.05.12\n",
    "grep HNF1A GWAS_catalog_2017.05.12 | wc -l\n",
    "\n",
    "grep 120987058 GWAS_catalog_2017.05.12 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 6\n",
    "\n",
    "# There is no single right answer here, you might have selected other search criteria that give the same result.\n",
    "grep -e DOWNSTREAM_GENE_DISTANCE -e 120987058 GWAS_catalog_2017.05.12| grep -e 2008-06-22 -e DOWNSTREAM_GENE_DISTANCE > 300th_line2.txt\n",
    "\n",
    "# The diff output is empty: our files are identical!\n",
    "diff 300th_line.txt 300th_line2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Playing with columns: cut and paste\n",
    "\n",
    "As we now know, our file contains many columns, but we are interested in only a couple of them. `cut` allows to extract specific columns from a file, whereas `paste` appends several columns together. The delimiter (space, comma, tab) that separates your fields is specified with the `-d` argument (as they are special characters they will need to be quoted with `'`).\n",
    "\n",
    "#### Example\n",
    "The below command extracts columns 1 to 4, 6, and 8 to 10 of `file.txt` and prints the output to the screen.\n",
    "```bash\n",
    "cut -f1-4,6,8-10 file.txt\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 7:</b> Extract the associated disease/trait and the SNP id (column `SNPS`) from the GWAS catalog and write them to a file called `phenotype_SNP.txt`. Then create a file called `SNP_phenotype.txt` where the SNP column comes first, and the Disease/trait one second (`cut` alone is not enough for this, you need to create 2 files and paste them together).\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cut -f8,22 GWAS_catalog_2017.05.12 > phenotype_SNP.txt\n",
    "\n",
    "cut -f8 GWAS_catalog_2017.05.12 > phenotype.txt\n",
    "cut -f22 GWAS_catalog_2017.05.12 > SNP.txt\n",
    "\n",
    "paste SNP.txt phenotype.txt > SNP_phenotype.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Find and replace\n",
    "\n",
    "Once we have extracted some data, we often want to modify it. There are 2 programs to do this type of thing, one very simple and the other very complicated:\n",
    "\n",
    "* `tr` replaces every occurrence of one particular character by another character\n",
    "*  * The syntax is very simple : `command1 | tr 'a' 'b' ` replaces every occurrence of the letter a in the pipe by the letter b.\n",
    "* `sed` is more complicated to use, but allows to substitute pretty much anything by pretty much anything else.\n",
    "*  * `command1 | sed 's/pattern_to_find/replacement pattern/'`\n",
    "*  * `pattern_to_find` is a **regular expression**, a special command that allow you to match certain bits of text an not others. Regular expressions are very, very common in the computing world, and many programs understand them (`grep` also allows them). Regular expressions (or regexes) can take a long time to learn and use properly. You can learn about them [here](http://www.regular-expressions.info/) and test them out [here](http://regexr.com/).\n",
    "\n",
    "### Some (very) basic regular expressions\n",
    "\n",
    "* `/Volos/` matches the string `Volos`, as expected\n",
    "* `/Vo*los/` matches Volos with zero or more first `o`: `Volos`, `Vlos` `Voooooooolos`\n",
    "* `/Vo+los/` matches Volos with one or more first `o`: `Volos`,  `Voooooooolos` but not `Vlos`\n",
    "* `/V.los/` matches Volos, but the second letter can be anything (but not nothing): `Volos`, `Vylos`, `Vvlos` but not `Voolos`\n",
    "* `/$/` matches the end of the line\n",
    "* `/^/` matches the beginning of the line\n",
    "* `/^Volos$/` matches a line that contains only `Volos` but not if there is a space (or anything) before or after.\n",
    "* `s/o/i/` will replace `Volos` by `Vilos`, but `s/o/i/g` will replace all occurrences of the pattern: `Volos` will become `Vilis`.\n",
    "* etc...\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 8:</b> Using `tr`, replace every space character in the GWAS catalog by an underscore (`_`) and write it to `GWAS_catalog_no_spaces.txt`. Remember they are special characters, so need to be quoted.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 9:</b> In the file `phenotype_SNP.txt` you generated before, some SNPs have several IDs separated by a semicolon. Find them and remove all alternate IDs, keeping only the first one; write the file to `duplicates_removed.txt`.\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 8\n",
    "cat GWAS_catalog_2017.05.12 | tr ' ' '_' > GWAS_catalog_no_spaces.txt\n",
    "\n",
    "## Question 9\n",
    "grep ';' phenotype_SNP.txt | sed 's/;.*//' > duplicates_removed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Advanced column manipulation using `awk`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# extracting variants that are associated with height:\n",
    "grep height filename\n",
    "grep -i height filename\n",
    "grep \n",
    "\n",
    "\n",
    "# extracting lines that are associated with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Temporarily storing a piece of information that we are going to refer later using its name. Two basic actions:\n",
    "1. Setting the value (assignment).\n",
    "2. Reading the value (The shell substitues the name of the variable with its value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 12\n",
      "2. 12\n",
      "3. 12\n",
      "gene_list_chr12_lst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: gene_list_chr: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Setting the value a local variable (no spaces around the = sign):\n",
    "chromosome=12 \n",
    "\n",
    "# Calling variable:\n",
    "echo 1. $chromosome\n",
    "echo 2. ${chromosome}\n",
    "echo 3. \"${chromosome}\"\n",
    "\n",
    "# When curly braces are needed:\n",
    "ls gene_list_chr$chromosome_lst # Warning message! The variable name is not separated from the rest of the string!\n",
    "ls gene_list_chr${chromosome}_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often automatic value assignment is required when the value is read derived from an other process. Imagine a list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%bash is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops\n",
    "\n",
    "Often we have to repeat a set of steps multiple times. In such cases loops are constructed to keep the code short and clean. In bash we mainly use the `for` and the `while` loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "Processing 20\n",
      "Processing 21\n",
      "Processing 22\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Repeating a process for all autosomes:\n",
    "for chr in {1..22}; do\n",
    "    echo Processing ${chr}\n",
    "    # Some commands... \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example using the curly braces, we generate a series of numbers between 1 and 22. Then in each this value is assigned to variable named `chr` in "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
