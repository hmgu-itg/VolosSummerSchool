{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "    var code_show=true; //true -> hide code at first\n",
    "\n",
    "    function code_toggle() {\n",
    "        $('div.prompt').hide(); // always hide prompt\n",
    "\n",
    "        if (code_show){\n",
    "            $('div.input').hide();\n",
    "        } else {\n",
    "            $('div.input').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    }\n",
    "    $( document ).ready(code_toggle);\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Workshop 1b: Advanced UNIX/Bash</h1><br><br>\n",
    "<i><big> File operations, pipes, data reformatting and queries.</big><br><br>\n",
    "Arthur Gilly (ag15@sanger.ac.uk), Kostas Hatzikotoulas (kh9@sanger.ac.uk)</i>\n",
    "</center>\n",
    "\n",
    "**Topics covered in this tutorial**:\n",
    "\n",
    "* Text processing tools: grep, cut, tr and paste.\n",
    "* Sed and AWK.\n",
    "* Pipes and redirections.\n",
    "\n",
    "**Topics _not_ covered in this tutorial**:\n",
    "\n",
    "* Variable handling.\n",
    "* Loops.\n",
    "* Conditionals.\n",
    "* Subshells, FIFO pipes and named pipes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Downloading resources from the internet\n",
    "\n",
    "It is easy to access the internet via the command line. For this we use the `wget` tool. We want to  download the complete [GWAS catalog](https://www.ebi.ac.uk/gwas/) maintained by [EBI](https://www.ebi.ac.uk/) that contains all the published genome-wide associations to date. This collection by 2017.05.12 contains 29,196 SNPs and 33,898 associations publised in 2,882 research articles. You can perform simple queries on the database using the GWAS catalog website, but you can also download it so you can build you own database. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 0:</b>  Go to the GWAS catalog website and find the download link. Create a directory in your home named `GWAS_catalog` and download it to a file named `GWAS_catalog_2017.05.12`. How large is the file you just downloaded?\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Goes to your home\n",
    "cd\n",
    "\n",
    "# Creates directory and enters it\n",
    "mkdir GWAS_catalog && cd GWAS_catalog\n",
    "\n",
    "# After the URL to the dataset, we specify the output file name.\n",
    "wget https://www.ebi.ac.uk/gwas/api/search/downloads/full -O GWAS_catalog_2017.05.12\n",
    "\n",
    "# Size\n",
    "ls -lh GWAS_catalog_2017.05.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> The `&&` operator allows you to execute several commands one after the other, but only if previous ones succeed. For example `command1 && command2 && command3` will execute `command2` only if `command1` succeeded, and `command3` only if both `command1` and `command2` succeeded.\n",
    "</div>\n",
    "\n",
    "`wget` is an extremely powerful bash tool, and has a wide range of amazing features (like resuming interrupted download) that we can't cover here. As it has been mentioned in the previous workshop, you can read the comprehensive manual using `man wget`. This also apply to the rest of the tools we are covering in this session.\n",
    "\n",
    "<div class=\"alert alert-warning\"> The file we just downloaded was created in Windows. This creates problems, because some characters are coded in different ways in UNIX/Linux and Windows. To make the file Linux-compatible, we do `dos2unix GWAS_catalog_2017.05.12`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing bash tools\n",
    "\n",
    "###  Step 2: Counting lines, first $n$ and last $n$ lines of a file\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 1:</b>  Using `wc`, check the number of lines in the GWAS catalog. Using `head` and `tail`, display the first 10 lines and the last 5 lines of the file.\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39690 GWAS_catalog_2017.05.12\n",
      "DATE ADDED TO CATALOG\tPUBMEDID\tFIRST AUTHOR\tDATE\tJOURNAL\tLINK\tSTUDY\tDISEASE/TRAIT\tINITIAL SAMPLE SIZE\tREPLICATION SAMPLE SIZE\tREGION\tCHR_ID\tCHR_POS\tREPORTED GENE(S)\tMAPPED_GENE\tUPSTREAM_GENE_ID\tDOWNSTREAM_GENE_ID\tSNP_GENE_IDS\tUPSTREAM_GENE_DISTANCE\tDOWNSTREAM_GENE_DISTANCE\tSTRONGEST SNP-RISK ALLELE\tSNPS\tMERGED\tSNP_ID_CURRENT\tCONTEXT\tINTERGENIC\tRISK ALLELE FREQUENCY\tP-VALUE\tPVALUE_MLOG\tP-VALUE (TEXT)\tOR or BETA\t95% CI (TEXT)\tPLATFORM [SNPS PASSING QC]\tCNV\n",
      "2009-09-28\t18403759\tOber C\t2008-04-09\tN Engl J Med\twww.ncbi.nlm.nih.gov/pubmed/18403759\tEffect of variation in CHI3L1 on serum YKL-40 level, risk of asthma, and lung function.\tYKL-40 levels\t632 Hutterite individuals\t443 European ancestry cases, 491 European ancestry controls, 206 European ancestry individuals\t1q32.1\t1\t203186754\tCHI3L1\tCHI3L1\t\t\t1116\t\t\trs4950928-G\trs4950928\t0\t4950928\tupstream_gene_variant\t0\t0.29\t1E-13\t13.0\t\t0.3\t[NR] ng/ml decrease\tAffymetrix [290325]\tN\n",
      "2008-06-16\t18369459\tLiu Y\t2008-04-04\tPLoS Genet\twww.ncbi.nlm.nih.gov/pubmed/18369459\tA genome-wide association study of psoriasis and psoriatic arthritis identifies new disease loci.\tPsoriasis\t218 European ancestry cases, 519 European ancestry controls\t1,153 European ancestry cases, 1,217 European ancestry controls\t13q14.11\t13\t39776775\tCOG6\tCOG6\t\t\t57511\t\t\trs7993214-?\trs7993214\t0\t7993214\tintron_variant\t0\t0.65\t2E-6\t5.698970004336019\t\t1.41\t[1.22-1.61]\tIllumina [305983]\tN\n",
      "2008-06-16\t18385676\tAmos CI\t2008-04-03\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/18385676\tGenome-wide association scan of tag SNPs identifies a susceptibility locus for lung cancer at 15q25.1.\tLung cancer\t1,154 European ancestry cases, 1,137 European ancestry controls\t2,724 European ancestry cases, 3,694 European ancestry controls\t15q25.1\t15\t78513681\tCHRNA5, CHRNA3, PSMA4, LOC123688\tHYKK\t\t\t123688\t\t\trs8034191-G\trs8034191\t0\t8034191\tintron_variant\t0\tNR\t3E-18\t17.522878745280337\t\t1.3\t[1.15-1.47]\tIllumina [317498]\tN\n",
      "2008-06-16\t18385676\tAmos CI\t2008-04-03\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/18385676\tGenome-wide association scan of tag SNPs identifies a susceptibility locus for lung cancer at 15q25.1.\tLung cancer\t1,154 European ancestry cases, 1,137 European ancestry controls\t2,724 European ancestry cases, 3,694 European ancestry controls\t1q23.2\t1\t159711078\tCRP\tCRPP1 - CRP\t171422\t1401\t\t5482\t1211\trs2808630-G\trs2808630\t0\t2808630\tdownstream_gene_variant\t1\tNR\t7E-6\t5.154901959985743\t\t1.22\t[1.10-1.35]\tIllumina [317498]\tN\n",
      "2008-06-16\t18385676\tAmos CI\t2008-04-03\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/18385676\tGenome-wide association scan of tag SNPs identifies a susceptibility locus for lung cancer at 15q25.1.\tLung cancer\t1,154 European ancestry cases, 1,137 European ancestry controls\t2,724 European ancestry cases, 3,694 European ancestry controls\t3q28\t3\t190632672\tIL1RAP\tIL1RAP\t\t\t3556\t\t\trs7626795-G\trs7626795\t0\t7626795\tintron_variant\t0\tNR\t8E-6\t5.096910013008056\t\t1.16\t[1.05-1.28]\tIllumina [317498]\tN\n",
      "2008-06-16\t18385738\tHung RJ\t2008-04-03\tNature\twww.ncbi.nlm.nih.gov/pubmed/18385738\tA susceptibility locus for lung cancer maps to nicotinic acetylcholine receptor subunit genes on 15q25.\tLung cancer\t1,926 European ance other ancestry cases, 2,522 European and other ancestry controls\t332 European ancestry cases, 462 European ancestry controls, 2,181 European and other ancestry cases, 4,290 European and other ancestry controls\t15q25.1\t15\t78513681\tCHRNA5, CHRNA3, PSMA4, LOC123688, CHRNB4\tHYKK\t\t\t123688\t\t\trs8034191-C\trs8034191\t0\t8034191\tintron_variant\t0\t0.34\t5E-20\t19.30102999566398\t\t1.3\t[1.23-1.37]\tIllumina [310023]\tN\n",
      "2008-09-16\t18385739\tThorgeirsson TE\t2008-04-03\tNature\twww.ncbi.nlm.nih.gov/pubmed/18385739\tA variant associated with nicotine dependence, lung cancer and peripheral arterial disease.\tNicotine dependence\t10,995 European ancestry individuals\t4,848 European ancestry individuals\t15q25.1\t15\t78601997\tCHRNA5, CHRNA3, CHRNB4\tCHRNA3\t\t\t1136\t\t\trs1051730-T\trs1051730\t0\t1051730\tsynonymous_variant\t0\t0.35\t6E-20\t19.221848749616356\t\t0.1\t[0.08-0.12] cigarettes per day increase\tIllumina [306207]\tN\n",
      "2008-06-16\t18372901\tTenesa A\t2008-03-30\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/18372901\tGenome-wide association scan identifies a colorectal cancer susceptibility locus on 11q23 and replicates risk loci at 8q24 and 18q21.\tColorectal cancer\t981 European ancestry cases, 1,002 European ancestry controls\t10,287 European ancestry cases, 10,401 European ancestry controls, 4,400 Japanese ancestry cases, 3,179 Japanese ancestry controls, 1,789 cases, 1,771 controls\t8q24.21\t8\t127412547\tPOU5FIP1, HsG57825, DQ515897\tCASC8\t\t\t727677\t\t\trs7014346-A\trs7014346\t0\t7014346\tintron_variant\t0\t0.18\t9E-26\t25.045757490560675\t\t1.19\t[1.15-1.23]\tIllumina [541628]\tN\n",
      "2008-06-16\t18372901\tTenesa A\t2008-03-30\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/18372901\tGenome-wide association scan identifies a colorectal cancer susceptibility locus on 11q23 and replicates risk loci at 8q24 and 18q21.\tColorectal cancer\t981 European ancestry cases, 1,002 European ancestry controls\t10,287 European ancestry cases, 10,401 European ancestry controls, 4,400 Japanese ancestry cases, 3,179 Japanese ancestry controls, 1,789 cases, 1,771 controls\t11q23.1\t11\t111300984\tintergenic\tCOLCA2, COLCA1\t\t\t120376, 399948\t\t\trs3802842-C\trs3802842\t0\t3802842\tintron_variant\t0\t0.43\t6E-10\t9.221848749616356\t\t1.11\t[1.08-1.15]\tIllumina [541628]\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t1q32.2\t1\t209818782\tIRF6\tIRF6 - DIEXF\t3664\t27042\t\t12607\t9185\trs12070337-?\trs12070337\t0\t12070337\tintergenic_variant\t1\tNR\t6E-12\t11.221848749616356\t(Asian)\t1.4705882\t\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t9q33.3\t9\t124748390\tIntergenic\tNR6A1\t\t\t2649\t\t\trs78427461-?\trs78427461\t0\t78427461\tintron_variant\t0\tNR\t8E-6\t5.096910013008056\t(Asian)\t1.41\t[1.23-1.62]\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t10q25.3\t10\t117057556\tVAX1\tKIAA1598\t\t\t57698\t\t\trs1898349-?\trs1898349\t0\t1898349\tintron_variant\t0\tNR\t1E-7\t7.0\t(Asian)\t1.35\t[1.21-1.49]\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t20q12\t20\t40656135\tMAFB\tLOC102724968 - LOC105372620\t102724968\t105372620\t\t12045\t21097\trs6029258-?\trs6029258\t0\t6029258\tintergenic_variant\t1\tNR\t6E-12\t11.221848749616356\t(Asian)\t1.4705882\t\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28067912\tLee JC\t2017-01-09\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/28067912\tGenome-wide association study identifies distinct genetic contributions to prognosis and susceptibility in Crohn's disease.\tPoor prognosis in Crohn's disease\t1,762 Northern European ancestry poor prognosis cases, 972 Northern European ancestry good prognosis controls.\t\t6q21\t6\t108666025\tFOXO3\tFOXO3\t\t\t2309\t\t\trs147856773-?\trs147856773\t0\t147856773\tintron_variant\t0\tNR\t1E-8\t8.0\t\t1.75\t[1.43-2.13]\tAffymetrix, Illumina [at least 7000000] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t1q32.2\t1\t209818782\tIRF6\tIRF6 - DIEXF\t3664\t27042\t\t12607\t9185\trs12070337-?\trs12070337\t0\t12070337\tintergenic_variant\t1\tNR\t6E-12\t11.221848749616356\t(Asian)\t1.4705882\t\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t9q33.3\t9\t124748390\tIntergenic\tNR6A1\t\t\t2649\t\t\trs78427461-?\trs78427461\t0\t78427461\tintron_variant\t0\tNR\t8E-6\t5.096910013008056\t(Asian)\t1.41\t[1.23-1.62]\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t10q25.3\t10\t117057556\tVAX1\tKIAA1598\t\t\t57698\t\t\trs1898349-?\trs1898349\t0\t1898349\tintron_variant\t0\tNR\t1E-7\t7.0\t(Asian)\t1.35\t[1.21-1.49]\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28054174\tLeslie EJ\t2017-01-04\tHum Genet\twww.ncbi.nlm.nih.gov/pubmed/28054174\tGenome-wide meta-analyses of nonsyndromic orofacial clefts identify novel associations between FOXE1 and all orofacial clefts, and TP63 and cleft lip with or without cleft palate.\tOrofacial clefts\t83 Asian ancestry cases, 1,445 Asian ancestry case-parent trios, 161 Asian ancestry controls, 208 European ancestry cases, 1,284 European ancestry case-parent trios, 835 European ancestry controls, 610 Latino or African cases, 663 Latino or African case-parent trios, 704 Latino or African controls, 35 case-parent trios.\tNA\t20q12\t20\t40656135\tMAFB\tLOC102724968 - LOC105372620\t102724968\t105372620\t\t12045\t21097\trs6029258-?\trs6029258\t0\t6029258\tintergenic_variant\t1\tNR\t6E-12\t11.221848749616356\t(Asian)\t1.4705882\t\tIllumina [6090031] (imputed)\tN\n",
      "2017-05-19\t28067912\tLee JC\t2017-01-09\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/28067912\tGenome-wide association study identifies distinct genetic contributions to prognosis and susceptibility in Crohn's disease.\tPoor prognosis in Crohn's disease\t1,762 Northern European ancestry poor prognosis cases, 972 Northern European ancestry good prognosis controls.\t\t6q21\t6\t108666025\tFOXO3\tFOXO3\t\t\t2309\t\t\trs147856773-?\trs147856773\t0\t147856773\tintron_variant\t0\tNR\t1E-8\t8.0\t\t1.75\t[1.43-2.13]\tAffymetrix, Illumina [at least 7000000] (imputed)\tN\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# How many lines does the file have?\n",
    "wc -l GWAS_catalog_2017.05.12\n",
    "\n",
    "# First 10 rows\n",
    "head GWAS_catalog_2017.05.12\n",
    "\n",
    "# Last 5 rows\n",
    "tail -5 GWAS_catalog_2017.05.12\n",
    "tail -n 5 GWAS_catalog_2017.05.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the first 10 rows we can see how the file is structured: \n",
    "* the first line is the header describing the content of each column (a more comprehensive explanation can be found on the [gwas website](https://www.ebi.ac.uk/gwas/docs/fileheaders))\n",
    "* then each line is an individual association between a genetic variant and an observed phenotype.\n",
    "\n",
    "### Step 3 : Using pipes\n",
    "\n",
    "Right now, all the commands we ran were printing their output to the screen (like `wc`) or to a file (`wget -O`). But we can also make the output go to another bash command. We do this using the \"pipe\" character (`|`). For example, `command1 | command2` will pass the output of `command1` to the input of `command2`. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 2:</b>  Using `head` piped to `tail`, print **only the 300th line** of the GWAS catalog. \n",
    "<br><br>\n",
    "`cat` prints the output of one or more files to the screen. Using `cat` and `wc`, print the number of lines in the GWAS catalog.\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-06-22\t18439548\tRidker PM\t2008-04-24\tAm J Hum Genet\twww.ncbi.nlm.nih.gov/pubmed/18439548\tLoci related to metabolic-syndrome pathways including LEPR,HNF1A, IL6R, and GCKR associate with plasma C-reactive protein: the Women's Genome Health Study.\tC-reactive protein\t6,345 European ancestry female individuals\tNA\t12q24.31\t12\t120987058\tHNF1A\tHNF1A\t\t\t6927\t\t\trs7310409-A\trs7310409\t0\t7310409\tintron_variant\t0\tNR\t7E-17\t16.154901959985743\t\t0.15\t[NR] mg/dl decrease\tIllumina [336108]\tN\r\n",
      "39690\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -300 GWAS_catalog_2017.05.12 | tail -1\n",
    "\n",
    "cat GWAS_catalog_2017.05.12 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : redirections\n",
    "\n",
    "Instead of ouputting the result of a command to another command, we can also tell UNIX to write the output to a file. This is not so useful when you have 1 command, but when you have several piped commands (pipeline) it is used to write the end result to a file. There are 2 types of redirection:\n",
    "\n",
    "* **overwrite** which is a single \"greater than\". `command1 > file` will overwrite `file` if it exists, otherwise create it and fill it with the output of `command1`.\n",
    "* **append**, which is a double \"greater than\". `command1 >> file` will add the output of `command1` to `file`, creating it if it does not exist.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 3:</b>  Using `head`, `tail` and pipes, create a file named `300th_line.txt` that contains **only the header and the 300th line**, and display it using `cat`.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE ADDED TO CATALOG\tPUBMEDID\tFIRST AUTHOR\tDATE\tJOURNAL\tLINK\tSTUDY\tDISEASE/TRAIT\tINITIAL SAMPLE SIZE\tREPLICATION SAMPLE SIZE\tREGION\tCHR_ID\tCHR_POS\tREPORTED GENE(S)\tMAPPED_GENE\tUPSTREAM_GENE_ID\tDOWNSTREAM_GENE_ID\tSNP_GENE_IDS\tUPSTREAM_GENE_DISTANCE\tDOWNSTREAM_GENE_DISTANCE\tSTRONGEST SNP-RISK ALLELE\tSNPS\tMERGED\tSNP_ID_CURRENT\tCONTEXT\tINTERGENIC\tRISK ALLELE FREQUENCY\tP-VALUE\tPVALUE_MLOG\tP-VALUE (TEXT)\tOR or BETA\t95% CI (TEXT)\tPLATFORM [SNPS PASSING QC]\tCNV\n",
      "2008-06-22\t18439548\tRidker PM\t2008-04-24\tAm J Hum Genet\twww.ncbi.nlm.nih.gov/pubmed/18439548\tLoci related to metabolic-syndrome pathways including LEPR,HNF1A, IL6R, and GCKR associate with plasma C-reactive protein: the Women's Genome Health Study.\tC-reactive protein\t6,345 European ancestry female individuals\tNA\t12q24.31\t12\t120987058\tHNF1A\tHNF1A\t\t\t6927\t\t\trs7310409-A\trs7310409\t0\t7310409\tintron_variant\t0\tNR\t7E-17\t16.154901959985743\t\t0.15\t[NR] mg/dl decrease\tIllumina [336108]\tN\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "## First the header\n",
    "head -1 GWAS_catalog_2017.05.12 > 300th_line.txt\n",
    "\n",
    "## Then the 300th line\n",
    "head -300 GWAS_catalog_2017.05.12 | tail -1 >> 300th_line.txt\n",
    "\n",
    "cat 300th_line.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><b>Question 4:</b> The file you have created contains both spaces and tab characters as separators, which makes it a bit messy to display. The `column` command can add artificial spaces to a pipe, so that it looks a bit more like Excel. Pipe `cat` into `column -s$'\\t' -t`, and then into `less`. By default, `less` folds long lines to make them fit the screen. We have very long lines so we want to display them laterally, without breaking them. Can you find the option in the `less` manual that does that? The 300th line of the GWAS catalog tells us about a mutation in a gene. Can you find the chromosome, position and gene for that variant?\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answer</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat 300th_line.txt | column -s$'\\t' -t | less -S\n",
    "\n",
    "# chromosome 12     position 120987058  gene HNF1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching files\n",
    "\n",
    "Very often, we want to search the contents of files. This is done using a very powerful command, `grep`.\n",
    "\n",
    "```bash\n",
    "\n",
    "grep [OPTIONS] [PATTERN] [FILE]\n",
    "\n",
    "# Example:\n",
    "\n",
    "grep Volos cities.txt\n",
    "```\n",
    "\n",
    "the last example looks for every line that contains \"Volos\" in the file `cities.txt` and displays the corresponding row. If your pattern contains a space, enclose it within simple or double quotes (e.g. `\"Volos, Thessalia\"` or `'Volos, Thessalia'`)\n",
    "\n",
    "<div class=\"alert alert-info\"> It is possible to search for several patterns at a time, not just one. If you are interested in only a few patterns, you can add them to the command line, separating them by `-e`. For example, ` grep -e Volos -e Thessaloniki cities.txt`. If you have many patterns that you want to search for, you can use `grep -f patterns.txt file.txt` where `patterns.txt` contains all the patterns you are interested in , 1 per line.\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-info\"> Interesting parameters for `grep` are `-w`, `-v`, `-i`, `-n`, `-A`, `-B`, `-C`, `-l` and `-L`. Check them out and play around with them if you have time!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 5:</b> Use `grep` to search for other variants in the gene you found above. Using a pipe and `wc`, determine how many lines from the GWAS ctalog mention it. How about the variant you found? Are there other lines that mention this variant?\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 6:</b> Before, we used 2 steps to create a file containing the 300th line. Now with `grep`, we can do everything in one line. Find something unique to the header and our 300th line, and create a file called `300th_line2.txt` that contains them (you might need several grep commands piped together). Use the `diff` command to check that the files are identical.\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 5\n",
    "grep HNF1A GWAS_catalog_2017.05.12\n",
    "grep HNF1A GWAS_catalog_2017.05.12 | wc -l\n",
    "\n",
    "grep 120987058 GWAS_catalog_2017.05.12 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 6\n",
    "\n",
    "# There is no single right answer here, you might have selected other search criteria that give the same result.\n",
    "grep -e DOWNSTREAM_GENE_DISTANCE -e 120987058 GWAS_catalog_2017.05.12| grep -e 2008-06-22 -e DOWNSTREAM_GENE_DISTANCE > 300th_line2.txt\n",
    "\n",
    "# The diff output is empty: our files are identical!\n",
    "diff 300th_line.txt 300th_line2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Playing with columns: cut and paste\n",
    "\n",
    "As we now know, our file contains many columns, but we are interested in only a couple of them. `cut` allows to extract specific columns from a file, whereas `paste` appends several columns together. The delimiter (space, comma, tab) that separates your fields is specified with the `-d` argument (as they are special characters they will need to be quoted with `'`).\n",
    "\n",
    "#### Example\n",
    "The below command extracts columns 1 to 4, 6, and 8 to 10 of `file.txt` and prints the output to the screen.\n",
    "```bash\n",
    "cut -f1-4,6,8-10 file.txt\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 7:</b> Extract the associated disease/trait and the SNP id (column `SNPS`) from the GWAS catalog and write them to a file called `phenotype_SNP.txt`. Then create a file called `SNP_phenotype.txt` where the SNP column comes first, and the Disease/trait one second (`cut` alone is not enough for this, you need to create 2 files and paste them together).\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cut -f8,22 GWAS_catalog_2017.05.12 > phenotype_SNP.txt\n",
    "\n",
    "cut -f8 GWAS_catalog_2017.05.12 > phenotype.txt\n",
    "cut -f22 GWAS_catalog_2017.05.12 > SNP.txt\n",
    "\n",
    "paste SNP.txt phenotype.txt > SNP_phenotype.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Find and replace\n",
    "\n",
    "Once we have extracted some data, we often want to modify it. There are 2 programs to do this type of thing, one very simple and the other very complicated:\n",
    "\n",
    "* `tr` replaces every occurrence of one particular character by another character\n",
    "*  * The syntax is very simple : `command1 | tr 'a' 'b' ` replaces every occurrence of the letter a in the pipe by the letter b.\n",
    "* `sed` is more complicated to use, but allows to substitute pretty much anything by pretty much anything else.\n",
    "*  * `command1 | sed 's/pattern_to_find/replacement pattern/'`\n",
    "*  * `pattern_to_find` is a **regular expression**, a special command that allow you to match certain bits of text an not others. Regular expressions are very, very common in the computing world, and many programs understand them (`grep` also allows them). Regular expressions (or regexes) can take a long time to learn and use properly. You can learn about them [here](http://www.regular-expressions.info/) and test them out [here](http://regexr.com/).\n",
    "\n",
    "### Some (very) basic regular expressions\n",
    "\n",
    "* `/Volos/` matches the string `Volos`, as expected\n",
    "* `/Vo*los/` matches Volos with zero or more first `o`: `Volos`, `Vlos` `Voooooooolos`\n",
    "* `/Vo+los/` matches Volos with one or more first `o`: `Volos`,  `Voooooooolos` but not `Vlos`\n",
    "* `/V.los/` matches Volos, but the second letter can be anything (but not nothing): `Volos`, `Vylos`, `Vvlos` but not `Voolos`\n",
    "* `/$/` matches the end of the line\n",
    "* `/^/` matches the beginning of the line\n",
    "* `/^Volos$/` matches a line that contains only `Volos` but not if there is a space (or anything) before or after.\n",
    "* `s/o/i/` will replace `Volos` by `Vilos`, but `s/o/i/g` will replace all occurrences of the pattern: `Volos` will become `Vilis`.\n",
    "* etc...\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 8:</b> Using `tr`, replace every space character in the GWAS catalog by an underscore (`_`) and write it to `GWAS_catalog_no_spaces.txt`. Remember they are special characters, so need to be quoted.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 9:</b> In the file `phenotype_SNP.txt` you generated before, some SNPs have several IDs separated by a semicolon. Find them and remove all alternate IDs, keeping only the first one; write the file to `duplicates_removed.txt`.\n",
    "</div>\n",
    "\n",
    "<button type=\"button\" class=\"btn btn-primary\" onClick=\"code_toggle()\">Click here to show/hide answers</button>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Question 8\n",
    "cat GWAS_catalog_2017.05.12 | tr ' ' '_' > GWAS_catalog_no_spaces.txt\n",
    "\n",
    "## Question 9\n",
    "grep ';' phenotype_SNP.txt | sed 's/;.*//' > duplicates_removed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Advanced column manipulation using `awk`\n",
    "\n",
    "Here, we introduce another very powerful tool: `awk`. Like `sed`, entire programs can be written in awk, so we will show only a tiny fraction of what can be done with it.\n",
    "\n",
    "The great usefulness of `awk` is that it **automatically splits lines on whitespace**, allowing you to select specific columns and performing actions on them.\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Beware:</b> `awk` splits on **any whitespace**. What will happen in a file like ours, with both tabs and spaces? Try it out: run `awk '{print $2}' GWAS_catalog_2017.05.12 | less`. Look at the first row. Is this what you would expect? What would you do to solve this problem?\n",
    "</div>\n",
    "\n",
    "### Some (very) basic examples\n",
    "\n",
    "\n",
    "* `'{print $2}'` prints the second field\n",
    "* `'{print $0}'` prints the whole line\n",
    "* `'$2==1'` prints the whole line if the second field is equal to 1 (equivalent to `'{if($2==1){print $0}}'`)\n",
    "* `'$3~/Volos/{print \"field 2 is: \", $2+1, \"field 3 is: \", $3}'` prints a custom string if the third field matches (contains) \"Volos\"\n",
    "* `'NF>2'` prints the line if it has more than 2 fields\n",
    "* `'$NF>2'` prints the line if the value of the last field is greater than 2\n",
    "* `'$10>$2+1 && $(NF-1)==\"yes\"'` prints the line if the 10th field is greater than the second + 1 **and** if the before-last field is equal to `yes`.\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<div class=\"alert alert-info\"> AWK commands, like `sed` ones, are enclosed within quotes (`'`). If you want to print the whole line only if a condition is satisfied, just write the condition. If you want to print certain columns, or do more complex operations, you must include your code in curly brackets (`{...}`).\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "<div class=\"alert alert-info\"> AWK merges consecutive delimiters into one. For example, in the string `a\\tb\\t\\tc`, `$2==\"b\"` and `$3==\"c\"`. Sometimes (as here) we might have empty fields, so we want to keep consecutive delimiters separated. To do that you have to tell awk specifically : `awk -F'\\t' '...'`\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 10:</b> Use the version of the GWAS catalog with no spaces we just created. How many fields does the GWAS catalog contain? Using `paste`, `tr` and `seq`, build a file named `column_indices.txt` that contains the column names and their numbers. With `grep`, locate the number of the columns `DISEASE/TRAIT`, `CHR_ID`, `CHR_POS`, `MAPPED_GENE`, `SNPS` in that file. Use awk to extract all records of the GWAS catalog that are on chromosome 11 between 5220000 and 5300000, and print only the fields above to a file called `Hemoglobin_region.txt`.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "DISEASE/TRAIT\t8\n",
      "CHR_ID\t12\n",
      "CHR_POS\t13\n",
      "MAPPED_GENE\t15\n",
      "SNPS\t22\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# number of fields (=34)\n",
    "head -1 GWAS_catalog_2017.05.12| tr ' ' '_' | awk '{print NF}'\n",
    "\n",
    "\n",
    "# building a file with column numbers\n",
    "head -1 GWAS_catalog_no_spaces.txt | tr '\\t' '\\n' > header.column\n",
    "seq 1 34 > indices.column\n",
    "paste header.column indices.column > header.columns\n",
    "\n",
    "# finding column IDs\n",
    "grep -w -e DISEASE -e CHR_ID -e CHR_POS -e MAPPED_GENE -e SNPS header.columns\n",
    "\n",
    "# Printing only selected fields\n",
    "awk -F'\\t' '$12==11 && $13>5220000 && $13<5300000{print $8, $12, $13, $15, $22}' GWAS_catalog_no_spaces.txt > Hemoglobin_region.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7:  Sorting\n",
    "\n",
    "Last but not least, we introduce the `sort` and `uniq` commands. Very often we need to sort files according to one or several columns, this is achieved using sort. Sort understands alphabetical, numerical and \"natural\" (i.e. scientific) orders and can compute unique values.\n",
    "\n",
    "#### Examples\n",
    "* `sort -k1,1 -k2,2n` sorts according to the first field (alphanumeric order) then the second field (numeric order)\n",
    "* `sort` sorts on the whole line according to alphanumeric order\n",
    "* `sort -r` sorts randomly\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\"> `uniq` does not add much to sort, as `sort -u` is the same as `sort | uniq`. `uniq` is frequently used for its `-c` argument, which counts the number of occurrences of every unique line.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\"><b>Question 11:</b> How many unique genes are there in our previous query? How many times is each of them mentioned?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 HBB\n",
      "      4 HBBP1\n",
      "      1 HBD\n",
      "      1 HBE1\n",
      "      4 LCRB\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cut -d' ' -f4 Hemoglobin_region.txt | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : Variables and loops\n",
    "\n",
    "In bash, we can define variables to store temporary information:\n",
    "\n",
    "```bash\n",
    "city=Volos\n",
    "```\n",
    "\n",
    "To recall the value of the variable we have to prefix it with a dollar sign (`$`):\n",
    "```bash\n",
    "echo $city\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Variable operations\n",
    "\n",
    "#### Concatenation\n",
    "This is the easiest of all operations: in order to \"glue\" the value of 2 variables together, simply write them one after the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "a=1\n",
    "b=2\n",
    "echo $a$b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also mix variables with text of your own:\n",
    "\n",
    "```bash\n",
    "Konstantinos lives in $city.\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Beware:</b> The character that follows your variable name is important. Bash will think that some characters are part of the variable name, for example you cannot write `$a-$b`, although you can write `$a.$b`. If you encounter such characters, you should write `${a}-${b}`.\n",
    "</div>\n",
    "\n",
    "#### Mathematical operations\n",
    "* Addition `$(( a + b ))`, `$(( 1 + 2 ))`\n",
    "* Other arithmetic operators `$(( a * b ))`, `$(( a / 10 ))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
