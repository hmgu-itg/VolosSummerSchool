{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1vAYXGLTzKJ"
      },
      "source": [
        "<script>\n",
        "    var code_show=true; //true -> hide code at first\n",
        "\n",
        "    function code_toggle() {\n",
        "        $('div.prompt').hide(); // always hide prompt\n",
        "\n",
        "        if (code_show){\n",
        "            $('div.input').hide();\n",
        "        } else {\n",
        "            $('div.input').show();\n",
        "        }\n",
        "        code_show = !code_show\n",
        "    }\n",
        "    $( document ).ready(code_toggle);\n",
        "</script>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3-Xj12iTzKM"
      },
      "source": [
        "<center>\n",
        "<h1>Workshop 1b: Advanced UNIX/Bash</h1><br><br>\n",
        "<i><big> File operations, pipes, data reformatting and queries.</big><br><br>\n",
        "William Rayner (william.rayner@helmholtz-muenchen.de), Young-Chan Park (young-chan.park@helmholtz-muenchen.de)</i>\n",
        "</center>\n",
        "\n",
        "**Topics covered in this tutorial**:\n",
        "\n",
        "* Text processing tools: `grep`, `cut`, `tr` and `paste`.\n",
        "* Sed and AWK.\n",
        "* Pipes and redirections.\n",
        "\n",
        "**Topics _not_ covered in this tutorial**:\n",
        "\n",
        "* Variable handling.\n",
        "* Loops.\n",
        "* Conditionals.\n",
        "* Subshells, FIFO pipes and named pipes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "lPmMDUThAia7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIrRwNz8TzKN"
      },
      "source": [
        "## Step 1 : Downloading resources from the internet\n",
        "\n",
        "It is easy to access the internet via the command line. For this we use the `wget` tool. We want to  download the complete [GWAS catalog](https://www.ebi.ac.uk/gwas/) maintained by [EBI](https://www.ebi.ac.uk/) that contains all the published genome-wide associations to date. This collection by 2022.11 contains at least 216,127 SNPS with dbSNP IDs (rsIDs) and 427,870 associations publised in 5,303 research articles. You can perform simple queries on the database using the GWAS catalog website, but you can also download it so you can build you own database. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 0  \n",
        "Go to the GWAS catalog website and find the download link. Create a directory in your home named `GWAS_catalog` and download it to a file named `GWAS_catalog_2022.11`. How large is the file you just downloaded?\n",
        "\n",
        "\n",
        "Click the arrow key besides the \"Question 0\" header to show/hide the answer. "
      ],
      "metadata": {
        "id": "K9qQVQRjF8X7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbZ_v7tITzKN"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# We suppress the output messages using the --quiet option\n",
        "# and specify the output file name using the -O option.\n",
        "wget --quiet -O GWAS_catalog.txt https://www.ebi.ac.uk/gwas/api/search/downloads/full\n",
        "\n",
        "# Size\n",
        "ls -lh GWAS_catalog.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O3RDTeITzKP"
      },
      "source": [
        "`wget` is an extremely powerful bash tool, and has a wide range of amazing features (like resuming interrupted download) that we can't cover here. As it has been mentioned in the previous workshop, you can read the comprehensive manual using `man wget`. This also apply to the rest of the tools we are covering in this session.\n",
        "\n",
        "<div class=\"alert alert-warning\"> The file we just downloaded was created in Windows. This creates problems, because some characters are coded in different ways in UNIX/Linux and Windows. To make the file Linux-compatible, we do `dos2unix GWAS_catalog.txt`.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text processing bash tools"
      ],
      "metadata": {
        "id": "3T1ZI9k5j0VE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVrEzEdcTzKP"
      },
      "source": [
        "## Step 2: Counting lines, first $n$ and last $n$ lines of a file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1  \n",
        "Using `wc`, check the number of lines in the GWAS catalog. Using `head` and `tail`, display the first 10 lines and the last 5 lines of the file.\n",
        "\n",
        "Click the arrow key besides the \"Step 2\" header to show/hide the answer. \n"
      ],
      "metadata": {
        "id": "vfHubsw5GJbk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2StY2F8yTzKP",
        "outputId": "ba53f8ab-dc17-4bda-d6b8-2819ebad3e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "427871 GWAS_catalog.txt\n",
            "DATE ADDED TO CATALOG\tPUBMEDID\tFIRST AUTHOR\tDATE\tJOURNAL\tLINK\tSTUDY\tDISEASE/TRAIT\tINITIAL SAMPLE SIZE\tREPLICATION SAMPLE SIZE\tREGION\tCHR_ID\tCHR_POS\tREPORTED GENE(S)\tMAPPED_GENE\tUPSTREAM_GENE_ID\tDOWNSTREAM_GENE_ID\tSNP_GENE_IDS\tUPSTREAM_GENE_DISTANCE\tDOWNSTREAM_GENE_DISTANCE\tSTRONGEST SNP-RISK ALLELE\tSNPS\tMERGED\tSNP_ID_CURRENT\tCONTEXT\tINTERGENIC\tRISK ALLELE FREQUENCY\tP-VALUE\tPVALUE_MLOG\tP-VALUE (TEXT)\tOR or BETA\t95% CI (TEXT)\tPLATFORM [SNPS PASSING QC]\tCNV\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t1q31.3\t1\t198253085\tNEK7\tNEK7\t\t\tENSG00000151414\t\t\trs55833332-G\trs55833332\t0\t55833332\tmissense_variant\t0\t0.0095\t5E-8\t7.301029995663981\t\t0.055339847\t[0.035-0.075] unit increase\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t1q31.3\t1\t198486261\tATP6V1G3\tNA - ATP6V1G3\t\tENSG00000263014\t\t\t36961\trs143554274-T\trs143554274\t0\t143554274\tintron_variant\t1\t0.0093\t1E-9\t9.0\t\t0.0618653\t[0.042-0.082] unit increase\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t1q41\t1\t219137119\tLYPLAL1-AS1\tLYPLAL1-DT\t\t\tENSG00000228063\t\t\trs12135454-T\trs12135454\t0\t12135454\tintron_variant\t0\t0.0095\t2E-8\t7.698970004336019\t\t0.0518954\t[0.034-0.07] unit decrease\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t1q41\t1\t219361143\tRP11-392O17.1\tNA - LYPLAL1-AS1\t\tENSG00000228536\t\t\t47896\trs12128471-A\trs12128471\t0\t12128471\tintergenic_variant\t1\t0.0091\t3E-9\t8.522878745280337\t\t0.0566545\t[0.038-0.075] unit decrease\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t4q23\t4\t98646767\tTSPAN5\tTSPAN5\t\t\tENSG00000168785\t\t\trs114026228-C\trs114026228\t0\t114026228\tintron_variant\t0\t0.0121\t5E-9\t8.301029995663981\t\t0.05772513\t[0.038-0.077] unit decrease\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t4q23\t4\t98830643\tEIF4E\tBTF3P13 - EIF4E\tENSG00000227118\tENSG00000151247\t\t89412\t48633\trs145441283-G\trs145441283\t0\t145441283\tintergenic_variant\t1\t0.0125\t2E-11\t10.698970004336019\t\t0.060972594\t[0.043-0.079] unit decrease\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t6q22.31\t6\t122018158\tHMGB3P18\t\t\t\t\t\t\trs187207161-C\trs187207161\t0\t187207161\tintergenic_variant\t1\t0.0098\t2E-10\t9.698970004336019\t\t0.056506313\t[0.039-0.074] unit decrease\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t8q24.12\t8\t119990436\tDEPTOR\tDEPTOR\t\t\tENSG00000155792\t\t\trs149165710-A\trs149165710\t0\t149165710\tintron_variant\t0\t0.0037\t3E-12\t11.522878745280337\t\t0.11488497\t[0.083-0.147] unit increase\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2021-09-21\t33230300\tSurendran P\t2020-11-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/33230300\tDiscovery of rare variants associated with blood pressure regulation through meta-analysis of 1.3 million individuals.\tPulse pressure\t445,360 European ancestry individuals\t225,112 European ancestry individuals\t10q25.1\t10\t104639382\tSORCS3\tNA - SORCS3\t\tENSG00000156395\t\t\t1908\trs535313355-C\trs535313355\t0\t535313355\tregulatory_region_variant\t1\t0.0087\t4E-9\t8.397940008672037\t\t0.05659966\t[0.038-0.076] unit increase\tIllumina [up to 29454346] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t9E-38\t37.045757490560675\t(328 ms)\t0.0706771\t[0.06-0.082] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t3E-37\t36.52287874528034\t(330 ms)\t0.070162\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t7E-37\t36.15490195998574\t(332 ms)\t0.0696095\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t4E-37\t36.39794000867204\t(334 ms)\t0.0697381\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t5p12\t5\t45014943\tMRPS30\t\t\t\t\t\t\trs111869282-C\trs111869282\t0\t111869282\tintergenic_variant\t1\t0.791595\t2E-8\t7.698970004336019\t(290 ms)\t0.0374742\t[0.024-0.051] unit increase\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t9E-38\t37.045757490560675\t(328 ms)\t0.0706771\t[0.06-0.082] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t3E-37\t36.52287874528034\t(330 ms)\t0.070162\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t7E-37\t36.15490195998574\t(332 ms)\t0.0696095\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t6q22.31\t6\t118346359\tSLC35F1\tSLC35F1 - CEP85L\tENSG00000196376\tENSG00000111860\t\t28683\t114413\trs11153730-T\trs11153730\t0\t11153730\tintergenic_variant\t1\t0.520014\t4E-37\t36.39794000867204\t(334 ms)\t0.0697381\t[0.059-0.081] unit decrease\tAffymetrix [10000000] (imputed)\tN\r\n",
            "2020-11-30\t32916098\tVerweij N\t2020-09-02\tCell Syst\twww.ncbi.nlm.nih.gov/pubmed/32916098\tThe Genetic Makeup of the Electrocardiogram.\tElectrocardiogram morphology (amplitude at temporal datapoints)\t63,706 European and unknown ancestry individuals\tNA\t5p12\t5\t45014943\tMRPS30\t\t\t\t\t\t\trs111869282-C\trs111869282\t0\t111869282\tintergenic_variant\t1\t0.791595\t2E-8\t7.698970004336019\t(290 ms)\t0.0374742\t[0.024-0.051] unit increase\tAffymetrix [10000000] (imputed)\tN\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# How many lines does the file have?\n",
        "wc -l GWAS_catalog.txt\n",
        "\n",
        "# First 10 rows\n",
        "head GWAS_catalog.txt\n",
        "\n",
        "# Last 5 rows\n",
        "tail -5 GWAS_catalog.txt\n",
        "tail -n 5 GWAS_catalog.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the first 10 rows we can see how the file is structured: \n",
        "* the first line is the header describing the content of each column (a more comprehensive explanation can be found on the [gwas website](https://www.ebi.ac.uk/gwas/docs/fileheaders))\n",
        "* then each line is an individual association between a genetic variant and an observed phenotype."
      ],
      "metadata": {
        "id": "i3vlkImKkgrS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQfdbjr8TzKQ"
      },
      "source": [
        "\n",
        "## Step 2b : Using pipes\n",
        "\n",
        "Right now, all the commands we ran were printing their output to the screen (like `wc`) or to a file (`wget -O`). But we can also make the output go to another bash command. We do this using the \"pipe\" character (`|`). For example, `command1 | command2` will pass the output of `command1` to the input of `command2`. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2  \n",
        "Using `head` piped to `tail`, print **only the 200th line** of the GWAS catalog. \n",
        "\n",
        "`cat` prints the output of one or more files to the screen. Using `cat` and `wc`, print the number of lines in the GWAS catalog.\n",
        "\n",
        "\n",
        "Click the arrow key besides the \"Question 2\" header to show/hide the answer. \n"
      ],
      "metadata": {
        "id": "gZlLzAJtGSS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBL2z102TzKR",
        "outputId": "abba62a4-9c66-434e-e6b6-e5a8ab619b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2018-10-19\t30038396\tLee JJ\t2018-07-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/30038396\tGene discovery and polygenic prediction from a genome-wide association study of educational attainment in 1.1 million individuals.\tEducational attainment (years of education)\tup to 1,131,881 European ancestry individuals\tNA\t1p31.1\t1\t74094727\t\tLRRIQ3\t\t\tENSG00000162620\t\t\trs10789387-A\trs10789387\t0\t10789387\tintron_variant\t0\t0.5379\t7E-16\t15.154901959985743\t(conditional-joint)\t0.0114\t[0.0087-0.0141] unit increase\tAffymetrix, Illumina [10000000] (imputed)\tN\r\n",
            "427871\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "head -200 GWAS_catalog.txt | tail -1\n",
        "\n",
        "cat GWAS_catalog.txt | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQHrtl7-TzKR"
      },
      "source": [
        "## Step 3 : redirections\n",
        "\n",
        "Instead of outputting the result of a command to another command, we can also tell UNIX to write the output to a file. This is not so useful when you have 1 command, but when you have several piped commands (pipeline) it is used to write the end result to a file. There are 2 types of redirection:\n",
        "\n",
        "* **overwrite** which is a single \"greater than\". `command1 > file` will overwrite `file` if it exists, otherwise create it and fill it with the output of `command1`.\n",
        "* **append**, which is a double \"greater than\". `command1 >> file` will add the output of `command1` to `file`, creating it if it does not exist.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "<div class=\"alert alert-success\">  Using `head`, `tail` and pipes, create a file named `200th_line.txt` that contains **only the header and the 200th line**, and display it using `cat`.\n",
        "\n",
        "</div>\n",
        "\n",
        "Click the arrow key besides the \"Step 3\" header to show/hide the answer. \n"
      ],
      "metadata": {
        "id": "M7oWPvAEmDa8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er9IYXB8TzKR",
        "outputId": "33572e60-cbb0-4cbb-e763-6d49fc8f2c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATE ADDED TO CATALOG\tPUBMEDID\tFIRST AUTHOR\tDATE\tJOURNAL\tLINK\tSTUDY\tDISEASE/TRAIT\tINITIAL SAMPLE SIZE\tREPLICATION SAMPLE SIZE\tREGION\tCHR_ID\tCHR_POS\tREPORTED GENE(S)\tMAPPED_GENE\tUPSTREAM_GENE_ID\tDOWNSTREAM_GENE_ID\tSNP_GENE_IDS\tUPSTREAM_GENE_DISTANCE\tDOWNSTREAM_GENE_DISTANCE\tSTRONGEST SNP-RISK ALLELE\tSNPS\tMERGED\tSNP_ID_CURRENT\tCONTEXT\tINTERGENIC\tRISK ALLELE FREQUENCY\tP-VALUE\tPVALUE_MLOG\tP-VALUE (TEXT)\tOR or BETA\t95% CI (TEXT)\tPLATFORM [SNPS PASSING QC]\tCNV\r\n",
            "2018-10-19\t30038396\tLee JJ\t2018-07-23\tNat Genet\twww.ncbi.nlm.nih.gov/pubmed/30038396\tGene discovery and polygenic prediction from a genome-wide association study of educational attainment in 1.1 million individuals.\tEducational attainment (years of education)\tup to 1,131,881 European ancestry individuals\tNA\t1p31.1\t1\t74094727\t\tLRRIQ3\t\t\tENSG00000162620\t\t\trs10789387-A\trs10789387\t0\t10789387\tintron_variant\t0\t0.5379\t7E-16\t15.154901959985743\t(conditional-joint)\t0.0114\t[0.0087-0.0141] unit increase\tAffymetrix, Illumina [10000000] (imputed)\tN\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "## First the header\n",
        "head -1 GWAS_catalog.txt > 200th_line.txt\n",
        "\n",
        "## Then the 200th line\n",
        "head -200 GWAS_catalog.txt | tail -1 >> 200th_line.txt\n",
        "\n",
        "cat 200th_line.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPWKczvTTzKS"
      },
      "source": [
        "### Question 4  \n",
        "The file you have created contains both spaces and tab characters as separators, which makes it a bit messy to display. The `column` command can add artificial spaces to a pipe, so that it looks a bit more like Excel. Pipe `cat` into `column -s$'\\t' -t`, and then into `less`. By default, `less` folds long lines to make them fit the screen. We have very long lines so we want to display them laterally, without breaking them. Can you find the option in the `less` manual that does that? The 200th line of the GWAS catalog tells us about a mutation in a gene. Can you find the chromosome, position and gene for that variant?\n",
        "\n",
        "\n",
        "Click the arrow key besides the \"Question 4\" header to show/hide the answer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z84PRD-bTzKS",
        "outputId": "711fe42d-7fef-4ace-a4a3-7b545ac42f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATE ADDED TO CATALOG  PUBMEDID  FIRST AUTHOR  DATE        JOURNAL    LINK                                  STUDY                                                                                                                               DISEASE/TRAIT                                INITIAL SAMPLE SIZE                            REPLICATION SAMPLE SIZE  REGION  CHR_ID  CHR_POS   REPORTED GENE(S)  MAPPED_GENE      UPSTREAM_GENE_ID  DOWNSTREAM_GENE_ID  SNP_GENE_IDS  UPSTREAM_GENE_DISTANCE  DOWNSTREAM_GENE_DISTANCE  STRONGEST SNP-RISK ALLELE  SNPS    MERGED  SNP_ID_CURRENT      CONTEXT              INTERGENIC  RISK ALLELE FREQUENCY          P-VALUE                                    PVALUE_MLOG  P-VALUE (TEXT)  OR or BETA  95% CI (TEXT)  PLATFORM [SNPS PASSING QC]  CNV\r\n",
            "2018-10-19             30038396  Lee JJ        2018-07-23  Nat Genet  www.ncbi.nlm.nih.gov/pubmed/30038396  Gene discovery and polygenic prediction from a genome-wide association study of educational attainment in 1.1 million individuals.  Educational attainment (years of education)  up to 1,131,881 European ancestry individuals  NA                       1p31.1  1       74094727  LRRIQ3            ENSG00000162620  rs10789387-A      rs10789387          0             10789387                intron_variant            0                          0.5379  7E-16   15.154901959985743  (conditional-joint)  0.0114      [0.0087-0.0141] unit increase  Affymetrix, Illumina [10000000] (imputed)  N\r\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat 200th_line.txt | column -s$'\\t' -t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UroPSHYTzKT"
      },
      "source": [
        "### Searching files\n",
        "\n",
        "Very often, we want to search the contents of files. This is done using a very powerful command, `grep`.\n",
        "\n",
        "```bash\n",
        "\n",
        "grep [OPTIONS] [PATTERN] [FILE]\n",
        "\n",
        "# Example:\n",
        "\n",
        "grep Munich cities.txt\n",
        "```\n",
        "\n",
        "the last example looks for every line that contains \"Munich\" in the file `cities.txt` and displays the corresponding row. If your pattern contains a space, enclose it within simple or double quotes (e.g. `\"Munich, Bavaria\"` or `'Munich, Thessalia'`)  \n",
        "\n",
        "It is possible to search for several patterns at a time, not just one. If you are interested in only a few patterns, you can add them to the command line, separating them by `-e`. For example, ` grep -e Munich -e Bavaria cities.txt`. If you have many patterns that you want to search for, you can use `grep -f patterns.txt file.txt` where `patterns.txt` contains all the patterns you are interested in, 1 per line.  \n",
        "\n",
        "Interesting parameters for `grep` are `-w`, `-v`, `-i`, `-n`, `-A`, `-B`, `-C`, `-l` and `-L`. Check them out and play around with them if you have time!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "<div class=\"alert alert-success\">Use `grep` to search for other variants in the gene you found above. Using a pipe and `wc`, determine how many lines from the GWAS catalog mention it. How about the variant you found? Are there other lines that mention this variant?\n",
        "</div>"
      ],
      "metadata": {
        "id": "XF_tnuvhqLIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKDNOHkpTzKT",
        "outputId": "b3d9cb85-09a4-421e-91db-d066a681ace3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "## Question 5\n",
        "grep LRRIQ3 GWAS_catalog.txt | wc -l\n",
        "\n",
        "grep 'rs10789387-A' GWAS_catalog.txt | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "Before, we used 2 steps to create a file containing the 200th line. Now with `grep`, we can do everything in one line. Find something unique to the header and our 200th line, and create a file called `200th_line2.txt` that contains them (you might need several grep commands piped together). Use the `diff` command to check that the files are identical."
      ],
      "metadata": {
        "id": "rVq_nJBWp_kT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjmvvitBTzKT"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "## Question 6\n",
        "\n",
        "# the -n option of grep is useful here to show which line has a match\n",
        "\n",
        "# There is no single right answer here, you might have selected other search criteria that give the same result.\n",
        "fgrep -e DOWNSTREAM_GENE_DISTANCE -e 'rs10789387-A' GWAS_catalog.txt > 200th_line2.txt\n",
        "\n",
        "# The diff output is empty: our files are identical!\n",
        "diff 200th_line.txt 200th_line2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gyX5vdkTzKT"
      },
      "source": [
        "## Step 4: Playing with columns: cut and paste\n",
        "\n",
        "As we now know, our file contains many columns, but we are interested in only a couple of them. `cut` allows to extract specific columns from a file, whereas `paste` appends several columns together. The delimiter (space, comma, tab) that separates your fields is specified with the `-d` argument (as they are special characters they will need to be quoted with `'`).\n",
        "\n",
        "#### Example\n",
        "The below command extracts columns 1 to 4, 6, and 8 to 10 of `file.txt` and prints the output to the screen.\n",
        "```bash\n",
        "cut -f1-4,6,8-10 file.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7  \n",
        "Extract the associated disease/trait and the SNP id (column `SNPS`) from the GWAS catalog and write them to a file called `phenotype_SNP.txt`. Then create a file called `SNP_phenotype.txt` where the SNP column comes first, and the Disease/trait one second (`cut` alone is not enough for this, you need to create 2 files and paste them together)."
      ],
      "metadata": {
        "id": "44NERfRs7dJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aQNhDMyTzKU",
        "outputId": "e75cf9ca-bde1-43aa-855c-2459daaea412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Content of phenotype_SNP.txt --\n",
            "DISEASE/TRAIT\tSNPS\n",
            "Pulse pressure\trs55833332\n",
            "Pulse pressure\trs143554274\n",
            "Pulse pressure\trs12135454\n",
            "\n",
            "-- Content of phenotype_SNP.txt --\n",
            "SNPS\tDISEASE/TRAIT\n",
            "rs55833332\tPulse pressure\n",
            "rs143554274\tPulse pressure\n",
            "rs12135454\tPulse pressure\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cut -f8,22 GWAS_catalog.txt > phenotype_SNP.txt\n",
        "\n",
        "cut -f8 GWAS_catalog.txt > phenotype.txt\n",
        "cut -f22 GWAS_catalog.txt > SNP.txt\n",
        "\n",
        "paste SNP.txt phenotype.txt > SNP_phenotype.txt\n",
        "\n",
        "echo -- Content of phenotype_SNP.txt --\n",
        "head -n 4 phenotype_SNP.txt\n",
        "echo\n",
        "echo -- Content of phenotype_SNP.txt --\n",
        "head -n 4 SNP_phenotype.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99-bmYWBTzKU"
      },
      "source": [
        "## Step 5 : Find and replace\n",
        "\n",
        "Once we have extracted some data, we often want to modify it. There are 2 programs to do this type of thing, one very simple and the other very complicated:\n",
        "\n",
        "* `tr` replaces every occurrence of one particular character by another character\n",
        "  * The syntax is very simple : `command1 | tr 'a' 'b' ` replaces every occurrence of the letter a in the pipe by the letter b.\n",
        "* `sed` is more complicated to use, but allows to substitute pretty much anything by pretty much anything else.\n",
        "  * `command1 | sed 's/pattern_to_find/replacement pattern/'`\n",
        "  * `pattern_to_find` is a **regular expression**, a special command that allow you to match certain bits of text and not others. Regular expressions are very, very common in the computing world, and many programs understand them (`grep` also allows them). Regular expressions (or regexes) can take a long time to learn and use properly. You can learn about them [here](http://www.regular-expressions.info/) and test them out [here](http://regexr.com/).\n",
        "\n",
        "### Some (very) basic regular expressions\n",
        "\n",
        "* `/Munich/` matches the string `Munich`, as expected\n",
        "* `/Mun*ich/` matches Munich with zero or more `n`: `Munich`, `Muich` `Munnnnnnich`\n",
        "* `/Mun+ich/` matches Munich with one or more `n`: `Munich`, `Munnnnnich` but not `Muich`\n",
        "* `/Mu.ich/` matches Munich, but the third letter can be anything (but not nothing): `Munich`, `Muyich`, `Muvich` but not `Munnich`\n",
        "* `/$/` matches the end of the line\n",
        "* `/^/` matches the beginning of the line\n",
        "* `/^Munich$/` matches a line that contains only `Munich` but not if there is a space (or anything) before or after.\n",
        "* `s/n/i/` will replace the first occurrence of `n` to `i`, so `Munich` to `Muiich`.\n",
        "* By adding a \"global\" flag like `s/a/i/g` (the `g` is the global flag), this changes the behaviour to replace all occurrences instead of one. So `s/a/i/g` will change `Bavaria` to `Bivirii`.\n",
        "* etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8 & 9\n",
        "\n",
        "<b>Question 8:</b> Using `tr`, replace every space character in the GWAS catalog by an underscore (`_`) and write it to `GWAS_catalog_no_spaces.txt`. Remember they are special characters, so need to be quoted.\n",
        "</div>\n",
        "\n",
        "<b>Question 9:</b> In the file `phenotype_SNP.txt` you generated before, some SNPs have several IDs separated by a semicolon. Find them and remove all alternate IDs, keeping only the first one; write the file to `duplicates_removed.txt`.\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "YXXu71v6tv93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUs5dzpBTzKU",
        "outputId": "f1c1a120-08e1-4009-f542-8e8ee8a77091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autism\trs2280840\n",
            "Autism\trs1545620\n",
            "Prostate cancer\trs1456305\n",
            "Hepatocellular carcinoma\tHLA_DRB1_0901\n",
            "F-cell distribution in sickle cell anaemia\trs10195871\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "## Question 8\n",
        "cat GWAS_catalog.txt | tr ' ' '_' > GWAS_catalog_no_spaces.txt\n",
        "\n",
        "## Question 9\n",
        "# It's not enough to just search for ';', because there are trait column \n",
        "# values with semi-colons included (e.g. 'Serum levels of protein TPSB2;TPSAB1').\n",
        "# So we write a simple regex to search\n",
        "grep -e '[0-9]; ' phenotype_SNP.txt | sed 's/;.*//' > duplicates_removed.txt\n",
        "\n",
        "head -n 5 duplicates_removed.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14mywuQATzKV"
      },
      "source": [
        "## Step 6 : Advanced column manipulation using `awk`\n",
        "\n",
        "Here, we introduce another very powerful tool: `awk`. Like `sed`, entire programs can be written in awk, so we will show only a tiny fraction of what can be done with it.\n",
        "\n",
        "The great usefulness of `awk` is that it **automatically splits lines on whitespace**, allowing you to select specific columns and performing actions on them.\n",
        "\n",
        "<b>Beware:</b> `awk` splits on **any whitespace**. What will happen in a file like ours, with both tabs and spaces? Try it out: run `awk '{print $2}' GWAS_catalog.txt | less`. Look at the first row. Is this what you would expect? What would you do to solve this problem?\n",
        "\n",
        "### Some (very) basic examples\n",
        "\n",
        "\n",
        "* `'{print $2}'` prints the second field\n",
        "* `'{print $0}'` prints the whole line\n",
        "* `'$2==1'` prints the whole line if the second field is equal to 1 (equivalent to `'{if($2==1){print $0}}'`)\n",
        "* `'$3~/Munich/{print \"field 2 is: \", $2+1, \"field 3 is: \", $3}'` prints a custom string if the third field matches (contains) \"Munich\"\n",
        "* `'NF>2'` prints the line if it has more than 2 fields\n",
        "* `'$NF>2'` prints the line if the value of the last field is greater than 2\n",
        "* `'$10>$2+1 && $(NF-1)==\"yes\"'` prints the line if the 10th field is greater than the second + 1 **and** if the before-last field is equal to `yes`.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "AWK commands, like `sed` ones, are enclosed within quotes (`'`). If you want to print the whole line only if a condition is satisfied, just write the condition. If you want to print certain columns, or do more complex operations, you must include your code in curly brackets (`{...}`).\n",
        "\n",
        "\n",
        "<br><br>\n",
        "AWK merges consecutive delimiters into one. For example, in the string `a\\tb\\t\\tc`, `$2==\"b\"` and `$3==\"c\"`. Sometimes (as here) we might have empty fields, so we want to keep consecutive delimiters separated. To do that you have to tell awk specifically : `awk -F'\\t' '...'`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 10\n",
        "Use the version of the GWAS catalog with no spaces we just created. How many fields does the GWAS catalog contain? Using `paste`, `tr` and `seq`, build a file named `column_indices.txt` that contains the column names and their numbers. With `grep`, locate the number of the columns `DISEASE/TRAIT`, `CHR_ID`, `CHR_POS`, `MAPPED_GENE`, `SNPS` in that file. Use awk to extract all records of the GWAS catalog that are on chromosome 11 between 5220000 and 5300000, and print only the fields above to a file called `Hemoglobin_region.txt`.\n"
      ],
      "metadata": {
        "id": "Jead2_kwv0bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzz3lJwgTzKV",
        "outputId": "d802605a-52d3-4802-8c70-f4b73519fbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of fields\n",
            "34\n",
            "\n",
            "Column numbers\n",
            "DISEASE/TRAIT\t8\n",
            "CHR_ID\t12\n",
            "CHR_POS\t13\n",
            "MAPPED_GENE\t15\n",
            "SNPS\t22\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# number of fields (=34)\n",
        "echo \"Number of fields\"\n",
        "head -1 GWAS_catalog.txt| tr ' ' '_' | awk '{print NF}'\n",
        "echo\n",
        "\n",
        "# building a file with column numbers\n",
        "head -1 GWAS_catalog_no_spaces.txt | tr '\\t' '\\n' > header.column\n",
        "seq 1 34 > indices.column\n",
        "paste header.column indices.column > header.columns\n",
        "\n",
        "# finding column IDs\n",
        "echo \"Column numbers\"\n",
        "grep -w -e DISEASE -e CHR_ID -e CHR_POS -e MAPPED_GENE -e SNPS header.columns\n",
        "\n",
        "# Printing only selected fields\n",
        "awk -F'\\t' '$12==11 && $13>5220000 && $13<5300000{print $8, $12, $13, $15, $22}' GWAS_catalog_no_spaces.txt > Hemoglobin_region.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrYii0gMTzKV"
      },
      "source": [
        "## Step 7:  Sorting\n",
        "\n",
        "Last but not least, we introduce the `sort` and `uniq` commands. Very often we need to sort files according to one or several columns, this is achieved using sort. Sort understands alphabetical, numerical and \"natural\" (i.e. scientific) orders and can compute unique values.\n",
        "\n",
        "#### Examples\n",
        "* `sort -k1,1 -k2,2n` sorts according to the first field (alphanumeric order) then the second field (numeric order)\n",
        "* `sort` sorts on the whole line according to alphanumeric order\n",
        "* `sort -r` sorts randomly\n",
        "\n",
        "<br>\n",
        "`uniq` does not add much to sort, as `sort -u` is the same as `sort | uniq`. `uniq` is frequently used for its `-c` argument, which counts the number of occurrences of every unique line.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 11\n",
        "How many unique genes are there in our previous query? How many times is each of them mentioned?"
      ],
      "metadata": {
        "id": "SCXwLD19wksg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxxYufbzTzKV",
        "outputId": "bf43d68a-bede-44b9-de8e-3c0c208e5bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      1 BGLT3_-_HBG1\n",
            "     83 HBB\n",
            "      1 HBBP1,_HBD\n",
            "      3 HBD\n",
            "      3 HBD,_HBBP1\n",
            "      8 HBE1,_HBG2\n",
            "     14 HBG2,_HBE1\n",
            "      1 No_mapped_genes_x_HBG2,_HBE1\n",
            "      1 OR51V1_-_HBB\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cut -d' ' -f4 Hemoglobin_region.txt | sort | uniq -c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT7QKoKxTzKV"
      },
      "source": [
        "## Step 8 : Variables and loops\n",
        "\n",
        "In bash, we can define variables to store temporary information:\n",
        "\n",
        "```bash\n",
        "city=Munich\n",
        "```\n",
        "\n",
        "To recall the value of the variable we have to prefix it with a dollar sign (`$`):\n",
        "```bash\n",
        "echo $city\n",
        "```\n",
        "\n",
        "### Variable operations\n",
        "\n",
        "#### Concatenation\n",
        "This is the easiest of all operations: in order to \"glue\" the value of 2 variables together, simply write them one after the other:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hwPhfmwTzKW",
        "outputId": "0ce23355-7c78-466b-956c-bb6203b8a8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "a=1\n",
        "b=2\n",
        "echo $a$b"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also mix variables with text of your own:"
      ],
      "metadata": {
        "id": "Sxk269Wm_Qgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "city=Munich\n",
        "\n",
        "echo Konstantinos lives in $city."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN5Up5GH_RxG",
        "outputId": "36cf8cf1-8776-4390-fdd6-3a737f3372ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Konstantinos lives in Munich.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAve4wMvTzKW"
      },
      "source": [
        "<b>Beware:</b> The character that follows your variable name is important. Bash will think that some characters are part of the variable name, for example you cannot write `$a-$b`, although you can write `$a.$b`. If you encounter such characters, you should write `${a}-${b}`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mathematical operations\n",
        "\n",
        "* Addition `$(( a + b ))`, `$(( 1 + 2 ))`\n",
        "* Other arithmetic operators `$(( a * b ))`, `$(( a / 10 ))`"
      ],
      "metadata": {
        "id": "nYErYEJp_dES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "a=1\n",
        "b=2\n",
        "echo Addition: $(( a + b ))\n",
        "echo Multiplication: $(( a * b ))\n",
        "echo Division: $(( a / b ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKo7k-ae_fq4",
        "outputId": "507865df-af69-48d4-fc28-59ace6e053fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: 3\n",
            "Multiplication: 2\n",
            "Division: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For loops\n",
        "\n",
        "For loops are used to iterate on a list of values:"
      ],
      "metadata": {
        "id": "sui2Scck_aoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV0tU4ijTzKW",
        "outputId": "6d751218-99e4-4725-c6f2-24322c31bc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "b\n",
            "c\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "for i in a b c; do\n",
        "    echo $i\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4F6BA-6TzKW"
      },
      "source": [
        "The value of a variable can contain spaces, or other separators. Bash interprets this as a list, so you can iterate over the values in a variable. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMa6IHp6TzKX",
        "outputId": "e5d8c236-a963-433c-d1a0-d9fa502dad25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "values=\"a b c d e f g h\"\n",
        "for v in $values; do\n",
        "    echo $v\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaDEWgh9TzKX"
      },
      "source": [
        "#### Special variables\n",
        "\n",
        "There are many \"special\" variables hidden in BASH. Some of them are set by the system, such as `$PATH`, which contains all the directories in which your system is going to look for commands. (a funny way to temporarily break your system is to set `PATH` to something random).\n",
        "\n",
        "Another special variable is the range operator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Db_eZ-sTzKX",
        "outputId": "29fe5794-2265-4800-c83a-2a12d5450a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "echo {1..22}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHoY56zATzKX"
      },
      "source": [
        "#### The `read` command\n",
        "\n",
        "The `read` command is a very powerful tool which reads whatever it receives through a pipe into a variable. We use it a lot in combination with the `while` loop when we want to **execute the same command on every line of a file**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noPQmOVuTzKX",
        "outputId": "82c6780f-7382-4bc3-bb4f-c34c3adadca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "echo -e \"a\\nb\\nc\\nd\\ne\\nf\\ng\" > test.txt\n",
        "cat test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1WUXCzyTzKX",
        "outputId": "4a0fbf78-a357-4024-81f6-f69cf187db13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat test.txt | while read letter; do\n",
        "    echo $letter\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4qmiL4zTzKY"
      },
      "source": [
        "`read` can also read several fields at the same time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZRSQJ0iTzKY",
        "outputId": "88631b30-3411-42a8-d87c-507c575b3462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\ta\n",
            "b\tb\n",
            "c\tc\n",
            "d\td\n",
            "e\te\n",
            "f\tf\n",
            "g\tg\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "paste test.txt test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl3zOlB-TzKY",
        "outputId": "7e0482f9-e39e-4189-a19f-eb7e81d77f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a a a a\n",
            "b b b b\n",
            "c c c c\n",
            "d d d d\n",
            "e e e e\n",
            "f f f f\n",
            "g g g g\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "paste test.txt test.txt | while read first second; do\n",
        "    echo $first $second $second $first\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8mhSL-lTzKY"
      },
      "source": [
        "The great use of this is that you can put whatever you want between `do` and `done` (many many commands, potentially). If you just have one quick command that you want to run, you can use `xargs` instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFbKg-QeTzKY",
        "outputId": "9cf6df36-d89c-4d80-e6ee-64cf421e85c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a b c d e f g\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "cat test.txt | xargs echo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1qw9kKTzKY"
      },
      "source": [
        "### Question 12 & 13\n",
        "\n",
        "<b>Question 12:</b>  \n",
        "Extract first 10 reported chromosome and position columns from the `GWAS_catalog.txt` file.\n",
        "\n",
        "\n",
        "<b>Question 13:</b>  \n",
        "For every chromosome, position (e.g. `1 1234`), convert this to a list of intervals extended by 1000 on either side (e.g. `1:234-2234`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "head -n 11 GWAS_catalog_no_spaces.txt | tail -n 10 | cut -f12,13 | while read chrom pos; do\n",
        "  echo \"${chrom}:$(( pos - 1000 ))-$(( pos + 1000 ))\"\n",
        "done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPVF1bgM9TBI",
        "outputId": "f9b8b8af-c689-4434-c352-e79c65eef5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1:198252085-198254085\n",
            "1:198485261-198487261\n",
            "1:219136119-219138119\n",
            "1:219360143-219362143\n",
            "4:98645767-98647767\n",
            "4:98829643-98831643\n",
            "6:122017158-122019158\n",
            "8:119989436-119991436\n",
            "10:104638382-104640382\n",
            "10:104760217-104762217\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K9qQVQRjF8X7",
        "vfHubsw5GJbk",
        "gZlLzAJtGSS8",
        "M7oWPvAEmDa8",
        "uPWKczvTTzKS",
        "3UroPSHYTzKT",
        "XF_tnuvhqLIJ",
        "rVq_nJBWp_kT",
        "44NERfRs7dJw",
        "YXXu71v6tv93",
        "Jead2_kwv0bc",
        "SCXwLD19wksg",
        "nYErYEJp_dES",
        "sui2Scck_aoQ",
        "SaDEWgh9TzKX",
        "GHoY56zATzKX",
        "rQ1qw9kKTzKY"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}